{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Lambda School Data Science — Classification & Validation_ \n",
    "\n",
    "# Random Forests & Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting and Random Forest are often the best choice for “Spreadsheet Machine Learning.”\n",
    "- Meaning, [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) for supervised learning with structured, tabular data.\n",
    "- Because trees can fit non-linear, non-monotonic relationships, and interactions between features.\n",
    "- A single decision tree, grown to unlimited depth, will overfit. We solve this problem by ensembling trees, with bagging or boosting.\n",
    "- One-hot encoding isn’t the only way, and may not be the best way, of categorical encoding for tree ensembles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "\n",
    "#### Decision Trees\n",
    "- A Visual Introduction to Machine Learning, [Part 1: A Decision Tree](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/),  and [Part 2: Bias and Variance](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)\n",
    "- [Decision Trees: Advantages & Disadvantages](https://christophm.github.io/interpretable-ml-book/tree.html#advantages-2)\n",
    "- [How decision trees work](https://brohrer.github.io/how_decision_trees_work.html)\n",
    "- [How a Russian mathematician constructed a decision tree - by hand - to solve a medical problem](http://fastml.com/how-a-russian-mathematician-constructed-a-decision-tree-by-hand-to-solve-a-medical-problem/)\n",
    "- [Let’s Write a Decision Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU)\n",
    "\n",
    "#### Random Forests\n",
    "- [Random Forests for Complete Beginners: The definitive guide to Random Forests and Decision Trees](https://victorzhou.com/blog/intro-to-random-forests/)\n",
    "- [Coloring with Random Forests](http://structuringtheunstructured.blogspot.com/2017/11/coloring-with-random-forests.html)\n",
    "- [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
    "\n",
    "#### Gradient Boosting\n",
    "- [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n",
    "- [A Kaggle Master Explains Gradient Boosting](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)\n",
    "- [How to explain gradient boosting](https://explained.ai/gradient-boosting/index.html)\n",
    "\n",
    "#### Python libraries for Gradient Boosting\n",
    "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the next version may be better](https://twitter.com/amuellerml/status/1123613520426426368)\n",
    "  - Anaconda: already installed\n",
    "  - Google Colab: already installed\n",
    "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
    "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
    "  - Windows: `pip install xgboost`\n",
    "  - Google Colab: already installed\n",
    "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
    "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
    "  - Google Colab: already installed\n",
    "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
    "  - Anaconda: `conda install -c conda-forge catboost`\n",
    "  - Google Colab: `pip install catboost`\n",
    "\n",
    "#### Categorical encoding for trees\n",
    "- [Are categorical variables getting lost in your random forests?](https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/)\n",
    "- [Beyond One-Hot: An Exploration of Categorical Variables](http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/)\n",
    "- [Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)\n",
    "- [Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)\n",
    "- [Mean (likelihood) encodings: a comprehensive study](https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study)\n",
    "- [The Mechanics of Machine Learning, Chapter 6: Categorically Speaking](https://mlbook.explained.ai/catvars.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Golf Putts (regression, 1 feature, non-linear)\n",
    "\n",
    "https://statmodeling.stat.columbia.edu/2008/12/04/the_golf_puttin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "putts = pd.DataFrame(\n",
    "    columns=['distance', 'tries', 'successes'], \n",
    "    data = [[2, 1443, 1346],\n",
    "            [3, 694, 577],\n",
    "            [4, 455, 337],\n",
    "            [5, 353, 208],\n",
    "            [6, 272, 149],\n",
    "            [7, 256, 136],\n",
    "            [8, 240, 111],\n",
    "            [9, 217, 69],\n",
    "            [10, 200, 67],\n",
    "            [11, 237, 75],\n",
    "            [12, 202, 52],\n",
    "            [13, 192, 46],\n",
    "            [14, 174, 54],\n",
    "            [15, 167, 28],\n",
    "            [16, 201, 27],\n",
    "            [17, 195, 31],\n",
    "            [18, 191, 33],\n",
    "            [19, 147, 20],\n",
    "            [20, 152, 24]]\n",
    ")\n",
    "\n",
    "putts['rate of success'] = putts['successes'] / putts['tries']\n",
    "putts_X = putts[['distance']]\n",
    "putts_y = putts['rate of success']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docs\n",
    "- [Scikit-Learn User Guide: Random Forests](https://scikit-learn.org/stable/modules/ensemble.html#random-forests) (`from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier`)\n",
    "- [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn) (`from xgboost import XGBRegressor, XGBClassifier`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d616d18710494889246fc1f4e530a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='max_depth', max=6, min=1), IntSlider(value=10, descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def putt_trees(max_depth=1, n_estimators=1):\n",
    "    models = [DecisionTreeRegressor(max_depth=max_depth), \n",
    "              RandomForestRegressor(max_depth=max_depth, n_estimators=n_estimators), \n",
    "              XGBRegressor(max_depth=max_depth, n_estimators=n_estimators)]\n",
    "    \n",
    "    for model in models:\n",
    "        name = model.__class__.__name__\n",
    "        model.fit(putts_X, putts_y)\n",
    "        ax = putts.plot('distance', 'rate of success', kind='scatter', title=name)\n",
    "        ax.step(putts_X, model.predict(putts_X), where='mid')\n",
    "        plt.show()\n",
    "        \n",
    "interact(putt_trees, max_depth=(1,6,1), n_estimators=(10,40,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Do-it-yourself Bagging Ensemble of Decision Trees (like a Random Forest)\n",
    "def diy_bagging(max_depth=1, n_estimators=1):\n",
    "    y_preds = []\n",
    "    for i in range(n_estimators):\n",
    "        title = f'Tree {i+1}'\n",
    "        bootstrap_sample = putts.sample(n=len(putts), replace=True).sort_values(by='distance')\n",
    "        bootstrap_X = bootstrap_sample[['distance']]\n",
    "        bootstrap_y = bootstrap_sample['rate of success']\n",
    "        tree = DecisionTreeRegressor(max_depth=max_depth)\n",
    "        tree.fit(bootstrap_X, bootstrap_y)\n",
    "        y_pred = tree.predict(bootstrap_X)\n",
    "        y_preds.append(y_pred)\n",
    "        ax = bootstrap_sample.plot('distance', 'rate of success', kind='scatter', title=title)\n",
    "        ax.step(bootstrap_X, y_pred, where='mid')\n",
    "        plt.show()\n",
    "        \n",
    "    ensembled = np.vstack(y_preds).mean(axis=0)\n",
    "    title = f'Ensemble of {n_estimators} trees, with max_depth={max_depth}'\n",
    "    ax = putts.plot('distance', 'rate of success', kind='scatter', title=title)\n",
    "    ax.step(putts_X, ensembled, where='mid')\n",
    "    plt.show()\n",
    "    \n",
    "interact(diy_bagging, max_depth=(1,6,1), n_estimators=(2,5,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's \"random\" about random forests?\n",
    "1. Each tree trains on a random bootstrap sample of the data. (In scikit-learn, for `RandomForestRegressor` and `RandomForestClassifier`, the `bootstrap` parameter's default is `True`.) This type of ensembling is called Bagging.\n",
    "2. Each split considers a random subset of the features. (In scikit-learn, when the `max_features` parameter is not `None`.) \n",
    "\n",
    "For extra randomness, you can try [\"extremely randomized trees\"](https://scikit-learn.org/stable/modules/ensemble.html#extremely-randomized-trees)!\n",
    "\n",
    ">In extremely randomized trees (see [ExtraTreesClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html) and [ExtraTreesRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html) classes), randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting \n",
    "\n",
    "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
    "\n",
    "[_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
    "\n",
    ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
    "\n",
    ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
    "\n",
    ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
    "\n",
    ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve fˆ in areas where it does not perform well.**\n",
    "\n",
    ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wave (regression, 1 feature, non-monotonic, train/test split)\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def make_data():\n",
    "    import numpy as np\n",
    "    rng = np.random.RandomState(1)\n",
    "    X = np.sort(5 * rng.rand(80, 1), axis=0)\n",
    "    y = np.sin(X).ravel()\n",
    "    y[::5] += 2 * (0.5 - rng.rand(16))\n",
    "    return X, y\n",
    "\n",
    "wave_X, wave_y = make_data()\n",
    "wave_X_train, wave_X_test, wave_y_train, wave_y_test = train_test_split(\n",
    "    wave_X, wave_y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave_trees(max_depth=1, n_estimators=10):\n",
    "    models = [DecisionTreeRegressor(max_depth=max_depth), \n",
    "              RandomForestRegressor(max_depth=max_depth, n_estimators=n_estimators), \n",
    "              XGBRegressor(max_depth=max_depth, n_estimators=n_estimators)]\n",
    "    \n",
    "    for model in models:\n",
    "        name = model.__class__.__name__\n",
    "        model.fit(wave_X_train, wave_y_train)\n",
    "        print(f'{name} Train R^2 score:', model.score(wave_X_train, wave_y_train))\n",
    "        print(f'{name} Test R^2 score:', model.score(wave_X_test, wave_y_test))\n",
    "        plt.scatter(wave_X_train, wave_y_train)\n",
    "        plt.scatter(wave_X_test, wave_y_test)\n",
    "        plt.step(wave_X, model.predict(wave_X), where='mid')\n",
    "        plt.show()\n",
    "        \n",
    "interact(wave_trees, max_depth=(1,8,1), n_estimators=(10,40,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic (classification, 2 features, interactions, non-linear / non-monotonic)\n",
    "\n",
    "#### viz2D helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz2D(fitted_model, X, feature1, feature2, num=100, title=''):\n",
    "    \"\"\"\n",
    "    Visualize model predictions as a 2D heatmap\n",
    "    For regression or binary classification models, fitted on 2 features\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fitted_model : scikit-learn model, already fitted\n",
    "    df : pandas dataframe, which was used to fit model\n",
    "    feature1 : string, name of feature 1\n",
    "    feature2 : string, name of feature 2\n",
    "    target : string, name of target\n",
    "    num : int, number of grid points for each feature\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    predictions: numpy array, predictions/predicted probabilities at each grid point\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    https://scikit-learn.org/stable/auto_examples/classification/plot_classification_probability.html\n",
    "    https://jakevdp.github.io/PythonDataScienceHandbook/04.04-density-and-contour-plots.html\n",
    "    \"\"\"\n",
    "    x1 = np.linspace(X[feature1].min(), X[feature1].max(), num)\n",
    "    x2 = np.linspace(X[feature2].min(), X[feature2].max(), num)\n",
    "    X1, X2 = np.meshgrid(x1, x2)\n",
    "    X = np.c_[X1.flatten(), X2.flatten()]\n",
    "    if hasattr(fitted_model, 'predict_proba'):\n",
    "        predicted = fitted_model.predict_proba(X)[:,1]\n",
    "    else:\n",
    "        predicted = fitted_model.predict(X)\n",
    "    \n",
    "    plt.imshow(predicted.reshape(num, num), cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(feature1)\n",
    "    plt.ylabel(feature2)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data, encode categorical feature, impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "features = ['age', 'sex']\n",
    "target = 'survived'\n",
    "\n",
    "preprocessor = make_pipeline(ce.OrdinalEncoder(), SimpleImputer())\n",
    "X = preprocessor.fit_transform(titanic[features])\n",
    "X = pd.DataFrame(X, columns=features)\n",
    "y = titanic[target]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X, y)\n",
    "viz2D(lr, X, feature1='age', feature2='sex', title='Logistic Regression');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree, Random Forest, Gradient Boosting\n",
    "\n",
    "#### Docs\n",
    "- [Scikit-Learn User Guide: Random Forests](https://scikit-learn.org/stable/modules/ensemble.html#random-forests) (`from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier`)\n",
    "- [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn) (`from xgboost import XGBRegressor, XGBClassifier`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def titanic_trees(max_depth=1, n_estimators=1):\n",
    "    models = [DecisionTreeClassifier(max_depth=max_depth), \n",
    "              RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators), \n",
    "              XGBClassifier(max_depth=max_depth, n_estimators=n_estimators)]\n",
    "    \n",
    "    for model in models:\n",
    "        name = model.__class__.__name__\n",
    "        model.fit(X.values, y.values)\n",
    "        viz2D(model, X, feature1='age', feature2='sex', title=name)\n",
    "        \n",
    "interact(titanic_trees, max_depth=(1,6,1), n_estimators=(10,40,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do-it-yourself Bagging Ensemble of Decision Trees (like a Random Forest)\n",
    "\n",
    "def titanic_bagging(max_depth=1, n_estimators=1):\n",
    "    predicteds = []\n",
    "    for i in range(n_estimators):\n",
    "        title = f'Tree {i+1}'\n",
    "        bootstrap_sample = titanic.sample(n=len(titanic), replace=True)\n",
    "        preprocessor = make_pipeline(ce.OrdinalEncoder(), SimpleImputer())\n",
    "        bootstrap_X = preprocessor.fit_transform(bootstrap_sample[['age', 'sex']])\n",
    "        bootstrap_y = bootstrap_sample['survived']\n",
    "        tree = DecisionTreeClassifier(max_depth=max_depth)\n",
    "        tree.fit(bootstrap_X, bootstrap_y)\n",
    "        predicted = viz2D(tree, X, feature1='age', feature2='sex', title=title)\n",
    "        predicteds.append(predicted)\n",
    "    \n",
    "    ensembled = np.vstack(predicteds).mean(axis=0)\n",
    "    title = f'Ensemble of {n_estimators} trees, with max_depth={max_depth}'\n",
    "    plt.imshow(ensembled.reshape(100, 100), cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('age')\n",
    "    plt.ylabel('sex')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "        \n",
    "interact(titanic_bagging, max_depth=(1,6,1), n_estimators=(2,5,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select more features, compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "titanic['deck'] = titanic['deck'].astype(str)\n",
    "features = ['age', 'sex', 'pclass', 'sibsp', 'parch', 'fare', 'deck', 'embark_town']\n",
    "target = 'survived'\n",
    "\n",
    "preprocessor = make_pipeline(ce.OrdinalEncoder(), SimpleImputer(), MinMaxScaler())\n",
    "titanic_X = preprocessor.fit_transform(titanic[features])\n",
    "titanic_X = pd.DataFrame(titanic_X, columns=features)\n",
    "titanic_y = titanic[target]\n",
    "\n",
    "titanic_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = [LogisticRegression(solver='lbfgs', max_iter=1000), \n",
    "          DecisionTreeClassifier(max_depth=3), \n",
    "          DecisionTreeClassifier(max_depth=None), \n",
    "          RandomForestClassifier(max_depth=3, n_estimators=100, n_jobs=-1, random_state=42), \n",
    "          RandomForestClassifier(max_depth=None, n_estimators=100, n_jobs=-1, random_state=42), \n",
    "          XGBClassifier(max_depth=3, n_estimators=100, n_jobs=-1, random_state=42)]\n",
    "\n",
    "for model in models:\n",
    "    print(model, '\\n')\n",
    "    score = cross_val_score(model, titanic_X, titanic_y, scoring='accuracy', cv=5).mean()\n",
    "    print('Cross-Validation Accuracy:', score, '\\n', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    name = model.__class__.__name__\n",
    "    model.fit(titanic_X, titanic_y)\n",
    "    if name == 'LogisticRegression':\n",
    "        coefficients = pd.Series(model.coef_[0], titanic_X.columns)\n",
    "        coefficients.sort_values().plot.barh(color='grey', title=name)\n",
    "        plt.show()\n",
    "    else:\n",
    "        importances = pd.Series(model.feature_importances_, titanic_X.columns)\n",
    "        title = f'{name}, max_depth={model.max_depth}'\n",
    "        importances.sort_values().plot.barh(color='grey', title=title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT\n",
    "\n",
    "**Train Random Forest and Gradient Boosting models**, on the Bank Marketing dataset. (Or another dataset of your choice, not used during this lesson.) You may use any Python libraries for Gradient Boosting.\n",
    "\n",
    "Then, you have many options!\n",
    "\n",
    "#### Keep improving your model\n",
    "- **Try new categorical encodings.**\n",
    "- Explore and visualize your data. \n",
    "- Wrangle [bad data](https://github.com/Quartz/bad-data-guide), outliers, and missing values.\n",
    "- Try engineering more features. You can transform, bin, and combine features. \n",
    "- Try selecting fewer features.\n",
    "\n",
    "#### Follow the links — learn by reading & doing\n",
    "- Links at the top of this notebook\n",
    "- Links in previous notebooks\n",
    "- Extra notebook for today, about **\"monotonic constraints\"** and \"early stopping\" with xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import category_encoders as ce\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,cross_val_predict, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score, roc_curve,classification_report, confusion_matrix, accuracy_score, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4119, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.313</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.855</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.959</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.191</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital          education default  housing     loan  \\\n",
       "0   30  blue-collar  married           basic.9y      no      yes       no   \n",
       "1   39     services   single        high.school      no       no       no   \n",
       "2   25     services  married        high.school      no      yes       no   \n",
       "3   38     services  married           basic.9y      no  unknown  unknown   \n",
       "4   47       admin.  married  university.degree      no      yes       no   \n",
       "\n",
       "     contact month day_of_week ...  campaign  pdays  previous     poutcome  \\\n",
       "0   cellular   may         fri ...         2    999         0  nonexistent   \n",
       "1  telephone   may         fri ...         4    999         0  nonexistent   \n",
       "2  telephone   jun         wed ...         1    999         0  nonexistent   \n",
       "3  telephone   jun         fri ...         3    999         0  nonexistent   \n",
       "4   cellular   nov         mon ...         1    999         0  nonexistent   \n",
       "\n",
       "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0         -1.8          92.893          -46.2      1.313       5099.1  no  \n",
       "1          1.1          93.994          -36.4      4.855       5191.0  no  \n",
       "2          1.4          94.465          -41.8      4.962       5228.1  no  \n",
       "3          1.4          94.465          -41.8      4.959       5228.1  no  \n",
       "4         -0.1          93.200          -42.0      4.191       5195.8  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = pd.read_csv('/Users/azel/Downloads/bank-additional/bank-additional.csv',sep=';')\n",
    "print(bank.shape)\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank['y'] = bank['y'].replace({'yes':1,'no':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bank.select_dtypes('number').drop(columns = 'y')\n",
    "y = bank['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111414042511967\n"
     ]
    }
   ],
   "source": [
    "max_depth = 4\n",
    "model = DecisionTreeClassifier(max_depth=max_depth).fit(X, y)\n",
    "score = cross_val_score(model, X , y, scoring = 'accuracy', cv = 5).mean()\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       734\n",
      "           1       0.83      0.64      0.73        90\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       824\n",
      "   macro avg       0.89      0.81      0.85       824\n",
      "weighted avg       0.94      0.95      0.94       824\n",
      "\n",
      "\n",
      "ROC_AUC Score:  0.901808862377664\n",
      "\n",
      "accuracy 0.9466019417475728\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>722</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>32</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                 722                  12\n",
       "Actual Positive                  32                  58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depth = 4\n",
    "model = DecisionTreeClassifier(max_depth=max_depth).fit(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_proba = cross_val_predict(model, X_train , y_train, method = 'predict_proba', cv = 5)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print('ROC_AUC Score: ', roc_auc_score(y_train, y_pred_proba))\n",
    "print()\n",
    "print('accuracy', accuracy_score(y_test, y_pred))\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    columns=['Predicted Negative', 'Predicted Positive'], \n",
    "    index=['Actual Negative', 'Actual Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9092011276992696\n"
     ]
    }
   ],
   "source": [
    "max_depth = 4\n",
    "max_est = 10\n",
    "\n",
    "model = RandomForestClassifier(max_depth = max_depth, \n",
    "                              n_estimators = max_est, \n",
    "                              n_jobs = -1, \n",
    "                              random_state = 42).fit(X,y)\n",
    "\n",
    "score = cross_val_score(model, X , y, scoring = 'accuracy', cv = 5).mean()\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       734\n",
      "           1       0.63      0.43      0.51        90\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       824\n",
      "   macro avg       0.78      0.70      0.73       824\n",
      "weighted avg       0.90      0.91      0.90       824\n",
      "\n",
      "\n",
      "ROC_AUC Score:  0.9147826513868356\n",
      "\n",
      "accuracy 0.9101941747572816\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>711</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>51</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                 711                  23\n",
       "Actual Positive                  51                  39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depth = 10\n",
    "max_est = 10\n",
    "\n",
    "model = (RandomForestClassifier(max_depth = max_depth, \n",
    "                              n_estimators = max_est, \n",
    "                              random_state = 42)\n",
    "         .fit(X_train,y_train))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_proba = cross_val_predict(model, X_train , y_train, method = 'predict_proba', cv = 5)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print('ROC_AUC Score: ', roc_auc_score(y_train, y_pred_proba))\n",
    "print()\n",
    "print('accuracy', accuracy_score(y_test, y_pred))\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    columns=['Predicted Negative', 'Predicted Positive'], \n",
    "    index=['Actual Negative', 'Actual Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111443498677512\n"
     ]
    }
   ],
   "source": [
    "max_depth = 4\n",
    "max_est = 10\n",
    "\n",
    "model = XGBClassifier(max_depth = max_depth, \n",
    "                              n_estimators = max_est, \n",
    "                              n_jobs = -1, \n",
    "                              random_state = 42).fit(X,y)\n",
    "\n",
    "score = cross_val_score(model, X , y, scoring = 'accuracy', cv = 5).mean()\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       734\n",
      "           1       0.66      0.48      0.55        90\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       824\n",
      "   macro avg       0.80      0.72      0.75       824\n",
      "weighted avg       0.91      0.92      0.91       824\n",
      "\n",
      "\n",
      "F-1 Score:  0.5548387096774193\n",
      "\n",
      "ROC_AUC Score:  0.9198063774224066\n",
      "\n",
      "accuracy 0.9162621359223301\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>712</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>47</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                 712                  22\n",
       "Actual Positive                  47                  43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depth = 15\n",
    "max_est = 10\n",
    "\n",
    "model = XGBClassifier(max_depth = max_depth, \n",
    "                              n_estimators = max_est, \n",
    "                              n_jobs = -1, \n",
    "                              random_state = 42).fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_proba = cross_val_predict(model, X_train , y_train, method = 'predict_proba', cv = 5)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print('F-1 Score: ', f1_score(y_test, y_pred))\n",
    "print()\n",
    "print('ROC_AUC Score: ', roc_auc_score(y_train, y_pred_proba))\n",
    "print()\n",
    "print('accuracy', accuracy_score(y_test, y_pred))\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    columns=['Predicted Negative', 'Predicted Positive'], \n",
    "    index=['Actual Negative', 'Actual Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[712  22]\n",
      " [ 47  43]]\n",
      "\n",
      "\n",
      "precision: , 0.6615384615384615\n",
      "recall:  0.4777777777777778\n",
      "F1 Score:  0.5548387096774193\n",
      "Accuracy:  0.9162621359223301\n"
     ]
    }
   ],
   "source": [
    "false_positive = ((y_pred == 1) & (y_test == 0)).sum()\n",
    "true_positive = ((y_pred == 1) & (y_test == 1)).sum()\n",
    "false_negative = ((y_pred == 0) & (y_test == 1)).sum()\n",
    "true_negative = ((y_pred == 0) & (y_test == 0)).sum()\n",
    "predicted_pos = (y_pred == 1).sum()\n",
    "actual_pos = (y_test == 1).sum()\n",
    "predicted_neg = (y_pred == 0).sum()\n",
    "actual_neg = (y_test == 0).sum()\n",
    "\n",
    "def precision (true_positive, predicted_pos):\n",
    "    return true_positive / predicted_pos\n",
    "\n",
    "def recall (true_positive, actual_pos):\n",
    "    return true_positive / actual_pos\n",
    "\n",
    "def accuracy (true_positive, true_negative, y_pred):\n",
    "    return (true_positive + true_negative) / len(y_pred)\n",
    "\n",
    "def F1 (true_positive, predicted_pos, actual_pos):\n",
    "    prec = precision(true_positive, predicted_pos)\n",
    "    rec  = recall(true_positive, actual_pos)\n",
    "    \n",
    "    return  2 * (prec * rec) / (prec + rec)\n",
    "\n",
    "\n",
    "print(np.array([[true_negative, false_positive],\n",
    "         [false_negative, true_positive]]))\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('precision: ,' , precision(true_positive, predicted_pos))\n",
    "print('recall: ' , recall(true_positive, actual_pos))\n",
    "print('F1 Score: ' , F1(true_positive, predicted_pos, actual_pos))\n",
    "print('Accuracy: ' , accuracy(true_positive, true_negative, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting from the top, with a pipeline. Whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.133681</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.269680</td>\n",
       "      <td>0.192469</td>\n",
       "      <td>0.153741</td>\n",
       "      <td>0.512287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.094977</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.602510</td>\n",
       "      <td>0.956916</td>\n",
       "      <td>0.859735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.062311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882307</td>\n",
       "      <td>0.376569</td>\n",
       "      <td>0.981179</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882307</td>\n",
       "      <td>0.376569</td>\n",
       "      <td>0.980499</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.414286</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.015921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.389322</td>\n",
       "      <td>0.368201</td>\n",
       "      <td>0.806349</td>\n",
       "      <td>0.877883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       job   marital  education  default  housing  loan  contact  \\\n",
       "0  0.171429  0.000000  0.000000   0.000000      0.0      0.0   0.0      0.0   \n",
       "1  0.300000  0.090909  0.333333   0.142857      0.0      0.5   0.0      1.0   \n",
       "2  0.100000  0.090909  0.000000   0.142857      0.0      0.0   0.0      1.0   \n",
       "3  0.285714  0.090909  0.000000   0.000000      0.0      1.0   0.5      1.0   \n",
       "4  0.414286  0.181818  0.000000   0.285714      0.0      0.0   0.0      0.0   \n",
       "\n",
       "      month  day_of_week  duration  campaign  pdays  previous  poutcome  \\\n",
       "0  0.000000         0.00  0.133681  0.029412    1.0       0.0       0.0   \n",
       "1  0.000000         0.00  0.094977  0.088235    1.0       0.0       0.0   \n",
       "2  0.111111         0.25  0.062311  0.000000    1.0       0.0       0.0   \n",
       "3  0.111111         0.00  0.004666  0.058824    1.0       0.0       0.0   \n",
       "4  0.222222         0.50  0.015921  0.000000    1.0       0.0       0.0   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n",
       "0      0.333333        0.269680       0.192469   0.153741     0.512287  \n",
       "1      0.937500        0.698753       0.602510   0.956916     0.859735  \n",
       "2      1.000000        0.882307       0.376569   0.981179     1.000000  \n",
       "3      1.000000        0.882307       0.376569   0.980499     1.000000  \n",
       "4      0.687500        0.389322       0.368201   0.806349     0.877883  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = pd.read_csv('/Users/azel/Downloads/bank-additional/bank-additional.csv',sep=';')\n",
    "bank['y'] = bank['y'].replace({'yes':1,'no':0})\n",
    "\n",
    "features = bank.drop(columns = 'y').columns\n",
    "target = 'y'\n",
    "\n",
    "preprocessor = make_pipeline(ce.OrdinalEncoder(), \n",
    "                             MinMaxScaler())\n",
    "\n",
    "X = preprocessor.fit_transform(bank[features])\n",
    "X = pd.DataFrame(X, columns = features)\n",
    "y = bank[target]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False) \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95       734\n",
      "           1       0.69      0.20      0.31        90\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       824\n",
      "   macro avg       0.80      0.59      0.63       824\n",
      "weighted avg       0.89      0.90      0.88       824\n",
      " \n",
      "\n",
      "F-1 Score:  0.31034482758620696 \n",
      "\n",
      "ROC_AUC Score:  0.9120002945691643 \n",
      "\n",
      "accuracy 0.9029126213592233 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>726</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                 726                   8\n",
       "Actual Positive                  72                  18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "print(model, '\\n')\n",
    "   \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = cross_val_predict(model, X_train , y_train, method = 'predict_proba', cv = 5)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred),'\\n')\n",
    "print('F-1 Score: ', f1_score(y_test, y_pred),'\\n')\n",
    "print('ROC_AUC Score: ', roc_auc_score(y_train, y_pred_proba),'\\n')\n",
    "print('accuracy', accuracy_score(y_test, y_pred),'\\n')\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    columns=['Predicted Negative', 'Predicted Positive'], \n",
    "    index=['Actual Negative', 'Actual Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "coefficients = pd.Series(model.coef_[0], X.columns)\n",
    "\n",
    "coefficients.sort_values().plot.barh(color='green', figsize = (12,6))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "print(model, '\\n')\n",
    "   \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = cross_val_predict(model, X_train , y_train, method = 'predict_proba', cv = 5)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred),'\\n')\n",
    "print('F-1 Score: ', f1_score(y_test, y_pred),'\\n')\n",
    "print('ROC_AUC Score: ', roc_auc_score(y_train, y_pred_proba),'\\n')\n",
    "print('accuracy', accuracy_score(y_test, y_pred),'\\n')\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    columns=['Predicted Negative', 'Predicted Positive'], \n",
    "    index=['Actual Negative', 'Actual Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       734\n",
      "           1       0.66      0.41      0.51        90\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       824\n",
      "   macro avg       0.80      0.69      0.73       824\n",
      "weighted avg       0.90      0.91      0.90       824\n",
      " \n",
      "\n",
      "F-1 Score:  0.5068493150684932 \n",
      "\n",
      "ROC_AUC Score:  0.9015270389945373 \n",
      "\n",
      "accuracy 0.912621359223301 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>715</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>53</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                 715                  19\n",
       "Actual Positive                  53                  37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depth = 4\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=max_depth).fit(X_test, y_test)\n",
    "\n",
    "print(model, '\\n')\n",
    "   \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = cross_val_predict(model, X_train , y_train, method = 'predict_proba', cv = 5)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred),'\\n')\n",
    "print('F-1 Score: ', f1_score(y_test, y_pred),'\\n')\n",
    "print('ROC_AUC Score: ', roc_auc_score(y_train, y_pred_proba),'\\n')\n",
    "print('accuracy', accuracy_score(y_test, y_pred),'\\n')\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    columns=['Predicted Negative', 'Predicted Positive'], \n",
    "    index=['Actual Negative', 'Actual Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       734\n",
      "           1       0.63      0.32      0.43        90\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       824\n",
      "   macro avg       0.78      0.65      0.69       824\n",
      "weighted avg       0.89      0.91      0.89       824\n",
      " \n",
      "\n",
      "F-1 Score:  0.4264705882352941 \n",
      "\n",
      "ROC_AUC Score:  0.9123628412328852 \n",
      "\n",
      "accuracy 0.9053398058252428 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>717</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>61</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                 717                  17\n",
       "Actual Positive                  61                  29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depth = 10\n",
    "max_est = 10\n",
    "\n",
    "model = (RandomForestClassifier(max_depth = max_depth, \n",
    "                              n_estimators = max_est, \n",
    "                              random_state = 42)\n",
    "         .fit(X_train,y_train))\n",
    "\n",
    "print(model, '\\n')\n",
    "   \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = cross_val_predict(model, X_train , y_train, method = 'predict_proba', cv = 5)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred),'\\n')\n",
    "print('F-1 Score: ', f1_score(y_test, y_pred),'\\n')\n",
    "print('ROC_AUC Score: ', roc_auc_score(y_train, y_pred_proba),'\\n')\n",
    "print('accuracy', accuracy_score(y_test, y_pred),'\\n')\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    columns=['Predicted Negative', 'Predicted Positive'], \n",
    "    index=['Actual Negative', 'Actual Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=15, min_child_weight=1, missing=None, n_estimators=10,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1) \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       734\n",
      "           1       0.64      0.50      0.56        90\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       824\n",
      "   macro avg       0.79      0.73      0.76       824\n",
      "weighted avg       0.91      0.92      0.91       824\n",
      " \n",
      "\n",
      "F-1 Score:  0.5625000000000001 \n",
      "\n",
      "ROC_AUC Score:  0.9181938000743977 \n",
      "\n",
      "accuracy 0.9150485436893204 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>709</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                 709                  25\n",
       "Actual Positive                  45                  45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depth = 15\n",
    "max_est = 10\n",
    "\n",
    "model = XGBClassifier(max_depth = max_depth, \n",
    "                              n_estimators = max_est, \n",
    "                              n_jobs = -1, \n",
    "                              random_state = 42).fit(X_train,y_train)\n",
    "\n",
    "print(model, '\\n')\n",
    "   \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = cross_val_predict(model, X_train , y_train, method = 'predict_proba', cv = 5)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred),'\\n')\n",
    "print('F-1 Score: ', f1_score(y_test, y_pred),'\\n')\n",
    "print('ROC_AUC Score: ', roc_auc_score(y_train, y_pred_proba),'\\n')\n",
    "print('accuracy', accuracy_score(y_test, y_pred),'\\n')\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    columns=['Predicted Negative', 'Predicted Positive'], \n",
    "    index=['Actual Negative', 'Actual Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57437503, 0.1860565 , 0.18274431, ..., 0.58734316, 0.18388513,\n",
       "       0.19359219], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Or"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
