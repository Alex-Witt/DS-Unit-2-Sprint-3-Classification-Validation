{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PC9RfopIWrc9"
   },
   "source": [
    " _Lambda School Data Science Unit 2_\n",
    " \n",
    " # Classification & Validation Sprint Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UV7ArLFQN84W"
   },
   "source": [
    "Follow the instructions for each numbered part to earn a score of 2. See the bottom of the notebook for a list of ways you can earn a score of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAZcbTtiUlkI"
   },
   "source": [
    "#### For this Sprint Challenge, you'll predict whether a person's income exceeds $50k/yr, based on census data.\n",
    "\n",
    "You can read more about the Adult Census Income dataset at the UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell to load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvV9VORbxyvu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = ['age', \n",
    "           'workclass', \n",
    "           'fnlwgt', \n",
    "           'education', \n",
    "           'education-num', \n",
    "           'marital-status', \n",
    "           'occupation', \n",
    "           'relationship', \n",
    "           'race', \n",
    "           'sex', \n",
    "           'capital-gain', \n",
    "           'capital-loss', \n",
    "           'hours-per-week', \n",
    "           'native-country', \n",
    "           'income']\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', \n",
    "                 header=None, names=columns)\n",
    "\n",
    "df['income'] = df['income'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 — Begin with baselines\n",
    "\n",
    "Split the data into an **X matrix** (all the features) and **y vector** (the target).\n",
    "\n",
    "(You _don't_ need to split the data into train and test sets here. You'll be asked to do that at the _end_ of Part 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = df.drop(columns = 'income').columns\n",
    "target = 'income'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxKfgx4ycb3c"
   },
   "source": [
    "What **accuracy score** would you get here with a **\"majority class baseline\"?** \n",
    " \n",
    "(You can answer this question either with a scikit-learn function or with a pandas function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oo31Remcq-x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K    0.75919\n",
       ">50K     0.24081\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy Score:  0.7591904425539756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "      # Taking the Majority option and using that as the prediciton. \n",
    "y_pred = [(y.mode()[0])]*len(y)\n",
    "\n",
    "print(\"Baseline Accuracy Score: \" ,accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KdxE1TrcriI"
   },
   "source": [
    "What **ROC AUC score** would you get here with a **majority class baseline?**\n",
    "\n",
    "(You can answer this question either with a scikit-learn function or with no code, just your understanding of ROC AUC.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILS0fN0Cctyc"
   },
   "source": [
    "##### The ROC AUC Score is 0.5\n",
    "\n",
    "The ROC AUC score is a metric used to evaluate **weighted** Classification problems. A ROC AUC of a majority or random guessing baseline will be 0.5. Therefore, for a model to perform better than this baseline, it needs to score higher than a 0.5. Hence, it is an easier metric to interpret for this kind of classification problem than Accuracy Score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqYNDtwKYhji"
   },
   "source": [
    "In this Sprint Challenge, you will use **\"Cross-Validation with Independent Test Set\"** for your model validaton method.\n",
    "\n",
    "First, **split the data into `X_train, X_test, y_train, y_test`**. You can include 80% of the data in the train set, and hold out 20% for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPKf86yDYf0t"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 — Modeling with Logistic Regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E_ATNJdqTCuZ"
   },
   "source": [
    "- You may do exploratory data analysis and visualization, but it is not required.\n",
    "- You may **use all the features, or select any features** of your choice, as long as you select at least one numeric feature and one categorical feature.\n",
    "- **Scale your numeric features**, using any scikit-learn [Scaler](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) of your choice.\n",
    "- **Encode your categorical features**. You may use any encoding (One-Hot, Ordinal, etc) and any library (category_encoders, scikit-learn, pandas, etc) of your choice.\n",
    "- You may choose to use a pipeline, but it is not required.\n",
    "- Use a **Logistic Regression** model.\n",
    "- Use scikit-learn's [**cross_val_score**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) function. For [scoring](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules), use **accuracy**.\n",
    "- **Print your model's cross-validation accuracy score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be selective with my features and use visualization later in the challenge when I attempt a 3. Until then, its quick and dirty. \n",
    "\n",
    "##### Since I plan on working towards the stretch goal, I am keeping X_test and y_test in a vault until then. Hence I am using X_train and y_train for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValAccuracy Score:  0.8305053960246398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "# Import all the things!\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "pipline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    MinMaxScaler(),\n",
    "    LogisticRegression(solver = 'lbfgs', max_iter = 1000)\n",
    ")\n",
    "\n",
    "print('CrossValAccuracy Score: ', cross_val_score(pipline, X_train, y_train, scoring = 'accuracy', cv = 3).mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 — Modeling with Tree Ensembles!\n",
    "\n",
    "Part 3 is the same as Part 2, except this time, use a **Random Forest** or **Gradient Boosting** classifier. You may use scikit-learn, xgboost, or any other library. Then, print your model's cross-validation accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAxxkjG7gACP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValAccuracy Score:  0.8182201346143773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# I'm using Random Forest. Gradient Boosting keeps crashing my Kernal. \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    MinMaxScaler(),\n",
    "    RandomForestClassifier(max_depth = 3, n_estimators = 3, random_state = 42)\n",
    ")\n",
    "\n",
    "print('CrossValAccuracy Score: ', cross_val_score(pipeline, X_train, y_train, scoring = 'accuracy', cv = 3).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jkyHoRIbEgRR"
   },
   "source": [
    "## Part 4 — Calculate classification metrics from a confusion matrix\n",
    "\n",
    "Suppose this is the confusion matrix for your binary classification model:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td colspan=\"2\" rowspan=\"2\"></td>\n",
    "    <td colspan=\"2\">Predicted</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Negative</td>\n",
    "    <td>Positive</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">Actual</td>\n",
    "    <td>Negative</td>\n",
    "    <td style=\"border: solid\">85</td>\n",
    "    <td style=\"border: solid\">58</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Positive</td>\n",
    "    <td style=\"border: solid\">8</td>\n",
    "    <td style=\"border: solid\"> 36</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhyMM5H-JpVB"
   },
   "source": [
    "Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZPwqdh2KUcB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6470588235294118"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True Positive + True Negative / Number Predicted\n",
    "\n",
    "(36 + 85 ) / (8 + 36 + 58 + 85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRWLfGcGKeQw"
   },
   "source": [
    "Calculate precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-FEZ4i_Kf_n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3829787234042553"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True Positive / Predicted Positive\n",
    "\n",
    "36 / (36 + 58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h_mH2NYDKi2C"
   },
   "source": [
    "Calculate recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4_wJGyjKkXJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True Positive / Actually Positive\n",
    "\n",
    "36 / (36 + 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KEaWsk5Kk9W"
   },
   "source": [
    "## BONUS — How you can earn a score of 3\n",
    "\n",
    "### Part 1\n",
    "Do feature engineering, to try improving your cross-validation score.\n",
    "\n",
    "### Part 2\n",
    "Experiment with feature selection, preprocessing, categorical encoding, and hyperparameter optimization, to try improving your cross-validation score.\n",
    "\n",
    "### Part 3\n",
    "Which model had the best cross-validation score? Refit this model on the train set and do a final evaluation on the held out test set — what is the test score? \n",
    "\n",
    "### Part 4\n",
    "Calculate F1 score and False Positive Rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "preprocessor = make_pipeline(ce.OrdinalEncoder(), MinMaxScaler())\n",
    "\n",
    "X = preprocessor.fit_transform(X_train)\n",
    "X = pd.DataFrame(X, columns = features)\n",
    "y = y_train\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "coefficients = pd.Series(model.coef_[0], X.columns)\n",
    "\n",
    "coefficients.sort_values().plot.barh(color='green', figsize = (12,6))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Native-Country, and Education seem to have a suspiciously small coefficient. Good candidates for feature engineering. \n",
    "\n",
    "Also, the NAN are replaced by ?. I'm going to work around that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1836\n",
       "fnlwgt               0\n",
       "education            0\n",
       "education-num        0\n",
       "marital-status       0\n",
       "occupation        1843\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital-gain         0\n",
       "capital-loss         0\n",
       "hours-per-week       0\n",
       "native-country     583\n",
       "income               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace(' ?' , np.nan).isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to bin native-country into 4 categories:\n",
    ">- Developed Nations\n",
    ">- Developing Nations\n",
    ">- US Citizen\n",
    ">- US Territory\n",
    "\n",
    "These are estimates as to the economic development of these countries 25 years ago, in the time frame of this sprint challenge. They are guesses and not empircal.  \n",
    "\n",
    "It'll be a One-Hot binning. I think that should work well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "developed = [' South', ' England', ' Canada',' Germany', ' Iran',' Italy', ' Poland',\n",
    "             ' Portugal',' France',' China', ' Japan',' Yugoslavia',' Scotland',' Greece',\n",
    "             ' Hong',' Ireland', ' Hungary', ' Holand-Netherlands']\n",
    "\n",
    "developing = [' Cuba', ' Jamaica', ' India',' Mexico',' Honduras',' Philippines',\n",
    "              ' Columbia', ' Cambodia', ' Thailand', ' Ecuador', ' Laos',' Taiwan', \n",
    "              ' Haiti',' Dominican-Republic',' El-Salvador',' Guatemala',' Peru',\n",
    "              ' Trinadad&Tobago',' Nicaragua', ' Vietnam',]\n",
    "\n",
    "US_citizen = [' United-States']\n",
    "\n",
    "US_territory = [' Puerto-Rico', ' Outlying-US(Guam-USVI-etc)']\n",
    "\n",
    "df['from_developed'] = df['native-country'].isin(developed)\n",
    "df['from_developing'] = df['native-country'].isin(developing)\n",
    "df['from_territory'] = df['native-country'].isin(US_territory)\n",
    "df['US_citizen'] = df['native-country'].isin(US_citizen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "below_HS = [' 11th',' 9th',' 7th-8th',' 5th-6th', ' 10th', ' 1st-4th',\n",
    "            ' Preschool', ' 12th']\n",
    "\n",
    "HS = [' HS-grad', ' Some-college']\n",
    "\n",
    "Undergrad = [' Bachelors',' Assoc-acdm', ' Assoc-voc']\n",
    "\n",
    "Advanced = [' Masters', 'Doctorate', ' Prof-school']\n",
    "\n",
    "df['below_HS'] = df['education'].isin(below_HS)\n",
    "df['HS'] = df['education'].isin(HS)\n",
    "df['Undergrad'] = df['education'].isin(Undergrad)\n",
    "df['Advanced'] = df['education'].isin(Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['age', 'workclass', 'fnlwgt','marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "       'capital-gain', 'capital-loss', 'hours-per-week','from_developed', 'from_developing', 'from_territory',\n",
    "       'US_citizen', 'below_HS', 'HS', 'Undergrad', 'Advanced']\n",
    "\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# A Fresh Train_test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype bool, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValAccuracy Score:  0.83050531643406\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessor = make_pipeline(ce.OrdinalEncoder(), MinMaxScaler())\n",
    "\n",
    "X = preprocessor.fit_transform(X_train)\n",
    "X = pd.DataFrame(X, columns = features)\n",
    "y = y_train\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "print('CrossValAccuracy Score: ', cross_val_score(model, X, y, scoring = 'accuracy', cv = 3).mean())\n",
    "\n",
    "coefficients = pd.Series(model.coef_[0], X.columns)\n",
    "\n",
    "coefficients.sort_values().plot.barh(color='green', figsize = (12,6))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, thats pretty much the same!\n",
    "\n",
    "I'll just try another Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype bool, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype bool, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValAccuracy Score:  0.8456694663891149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype bool, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# A quick pipeline to mess with hyper-parameters. \n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    MinMaxScaler(),\n",
    "    RandomForestClassifier(max_depth = 5, n_estimators = 10, random_state = 42)\n",
    ")\n",
    "\n",
    "print('CrossValAccuracy Score: ', cross_val_score(pipeline, X_train, y_train, scoring = 'accuracy', cv = 3).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype bool, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype bool, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.87      0.95      0.91      4945\n",
      "        >50K       0.78      0.57      0.66      1568\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      6513\n",
      "   macro avg       0.83      0.76      0.78      6513\n",
      "weighted avg       0.85      0.86      0.85      6513\n",
      " \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-dd1095b139a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#print('F-1 Score: ', f1_score(y_test, y_pred),'\\n')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ROC_AUC Score: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m display(pd.DataFrame(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Now let's look at all the info using the train_test split. \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "max_depth = 10\n",
    "max_est = 10\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns = features)\n",
    "X_test = preprocessor.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns = features)\n",
    "\n",
    "model = (RandomForestClassifier(max_depth = max_depth, \n",
    "                              n_estimators = max_est, \n",
    "                              random_state = 42)\n",
    "         .fit(X_train,y_train))\n",
    "\n",
    "print(model, '\\n')\n",
    "   \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = cross_val_predict(model, X_train , y_train, method = 'predict_proba', cv = 5)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred),'\\n')\n",
    "#print('F-1 Score: ', f1_score(y_test, y_pred),'\\n')\n",
    "print('ROC_AUC Score: ', roc_auc_score(y_train, y_pred_proba),'\\n')\n",
    "print('accuracy', accuracy_score(y_test, y_pred),'\\n')\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    columns=['Predicted Negative', 'Predicted Positive'], \n",
    "    index=['Actual Negative', 'Actual Positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a big slice of missed predictions were false negatives making my recall go way down. It might be worth playing with the model more to bring the recall down. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Unit_2_Sprint_Challenge_4_Model_Validation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
